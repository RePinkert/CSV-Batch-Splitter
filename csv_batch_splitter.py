import csv
import json
import os
from datetime import datetime

import pandas as pd  # pip install pandas openpyxl

# ===== é…ç½®åŒº =====
CSV_PATH = "ue.csv"          # ä¸»è¡¨è·¯å¾„ï¼ˆç›¸å¯¹äºå½“å‰ç›®å½•ï¼‰
STATE_FILE = "state.json"    # ä¿å­˜ä¸»è¡¨å¾ªç¯è¿›åº¦
LOG_FILE = "send_log.csv"    # æ¯æ—¥æ‰¹æ¬¡æ—¥å¿—

MAX_RECIPIENTS_PER_EMAIL = 200
MAX_EMAILS_PER_DAY = 20
HAS_HEADER = True            # ä¸» CSV æ˜¯å¦æœ‰è¡¨å¤´
# ===== é…ç½®åŒºç»“æŸ =====


def find_csv_file():
    """è‡ªåŠ¨æŸ¥æ‰¾CSVæ–‡ä»¶ - ä¼˜å…ˆä½¿ç”¨ue.csv"""
    # é¦–å…ˆå°è¯•é…ç½®çš„è·¯å¾„
    if os.path.exists(CSV_PATH):
        return CSV_PATH
    
    # å¦‚æœé…ç½®çš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•å½“å‰ç›®å½•ä¸‹çš„CSVæ–‡ä»¶
    csv_files = [f for f in os.listdir('.') if f.lower().endswith('.csv')]
    
    # ä¼˜å…ˆæŸ¥æ‰¾ue.csvï¼ˆæºæ•°æ®æ–‡ä»¶ï¼‰
    ue_csv_candidates = [f for f in csv_files if f.lower() in ['ue.csv', 'ue.CSV']]
    if ue_csv_candidates:
        print(f"âœ… æ‰¾åˆ°æºæ•°æ®æ–‡ä»¶: {ue_csv_candidates[0]}")
        return ue_csv_candidates[0]
    
    # å¦‚æœæ²¡æœ‰ue.csvï¼Œæä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
    if csv_files:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æºæ•°æ®æ–‡ä»¶ 'ue.csv'")
        print(f"   å½“å‰ç›®å½•å‘ç°çš„CSVæ–‡ä»¶: {csv_files}")
        print(f"   è¯·å°†æºæ•°æ®æ–‡ä»¶é‡å‘½åä¸º 'ue.csv'ï¼Œæˆ–åˆ é™¤å…¶ä»–CSVæ–‡ä»¶")
        return None
    
    return None

def load_csv():
    """åŠ è½½ä¸» CSVï¼Œè¿”å› headerï¼ˆå¯èƒ½ä¸º Noneï¼‰ã€æ•°æ®è¡Œåˆ—è¡¨"""
    csv_file = find_csv_file()
    
    if not csv_file:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°CSVæ–‡ä»¶")
        print(f"   è¯·ç¡®ä¿å½“å‰ç›®å½•ä¸‹æœ‰CSVæ–‡ä»¶ï¼Œæˆ–å°†CSVæ–‡ä»¶é‡å‘½åä¸º '{CSV_PATH}'")
        return None, []
    
    try:
        with open(csv_file, newline="", encoding="utf-8") as f:
            reader = list(csv.reader(f))
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ '{csv_file}'")
        return None, []
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šè¯»å–CSVæ–‡ä»¶å¤±è´¥ - {e}")
        return None, []
    
    if not reader:
        print(f"âš ï¸  è­¦å‘Šï¼šCSVæ–‡ä»¶ '{csv_file}' ä¸ºç©º")
        return None, []
    
    if HAS_HEADER:
        header = reader[0]
        rows = reader[1:]
    else:
        header = None
        rows = reader
    
    print(f"âœ… æˆåŠŸåŠ è½½CSVæ–‡ä»¶: {csv_file}ï¼Œå…± {len(rows)} æ¡è®°å½•")
    return header, rows


def load_state():
    """åŠ è½½è¿›åº¦ï¼šå½“å‰å·²ç»ç”¨åˆ°çš„æ•°æ®è¡Œç´¢å¼•ï¼ˆä» 0 å¼€å§‹ï¼‰"""
    if not os.path.exists(STATE_FILE):
        return {"current_index": 0}
    with open(STATE_FILE, "r", encoding="utf-8") as f:
        return json.load(f)


def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def init_log_file_if_needed():
    """å¦‚æœæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå¹¶å†™å…¥è¡¨å¤´"""
    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["date", "batch_no", "count", "excel_start_row", "excel_end_row"])


def get_today_batch_count():
    """ç»Ÿè®¡ä»Šå¤©å·²ç»ç”Ÿæˆäº†å¤šå°‘ä¸ªExcelæ–‡ä»¶ï¼ˆä»æ—¥å¿—é‡Œçœ‹ï¼‰"""
    if not os.path.exists(LOG_FILE):
        return 0
    today = datetime.now().strftime("%Y-%m-%d")
    batch_numbers = set()  # ä½¿ç”¨setå»é‡
    
    with open(LOG_FILE, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row.get("date") == today:
                batch_no = row.get("batch_no", "")
                # æå–æ‰¹æ¬¡å·ä¸»å¹²ï¼ˆå»æ‰"-1", "-2"åç¼€ï¼‰
                base_batch_no = batch_no.split('-')[0]
                if base_batch_no:
                    batch_numbers.add(base_batch_no)
    
    return len(batch_numbers)


def append_log(date_str, batch_no, count, start_idx, end_idx):
    with open(LOG_FILE, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([date_str, batch_no, count, start_idx, end_idx])


def main():
    # 1. è¯»ä¸»è¡¨
    header, rows = load_csv()
    total = len(rows)
    print(f"ä¸»è¡¨æ€»è®°å½•æ•°: {total}")

    if total == 0:
        print("ä¸» CSV æ²¡æœ‰æ•°æ®ï¼Œé€€å‡ºã€‚")
        return

    # 2. è¯»è¿›åº¦
    state = load_state()
    current_index = state.get("current_index", 0)

    # å¦‚æœåˆ°è¾¾æœ«å°¾ï¼Œåˆ™å¾ªç¯ä»å¤´å¼€å§‹
    if current_index >= total:
        print("ğŸ”„ å·²åˆ°è¾¾è¡¨æœ«å°¾ï¼Œä»è¡¨å¤´å¼€å§‹å¾ªç¯åˆ‡åˆ†")
        current_index = 0
        state["current_index"] = 0
        save_state(state)

    # 3. æ£€æŸ¥ä»Šå¤©çš„æ‰¹æ¬¡æ•°é‡
    init_log_file_if_needed()
    today = datetime.now().strftime("%Y-%m-%d")
    today_batches = get_today_batch_count()
    print(f"ä»Šå¤©å·²ç”Ÿæˆæ‰¹æ¬¡æ•°: {today_batches}")

    if today_batches >= MAX_EMAILS_PER_DAY:
        print(f"ä»Šå¤©çš„ä¸Šé™ {MAX_EMAILS_PER_DAY} æ‰¹å·²ç»ç”¨å®Œï¼Œä¸å†ç”Ÿæˆæ–°æ–‡ä»¶ã€‚")
        return

    # 4. æ£€æŸ¥CSVæ–‡ä»¶å¤§å°æ˜¯å¦åˆç†
    if total <= MAX_RECIPIENTS_PER_EMAIL:
        print(f"âŒ é”™è¯¯ï¼šCSVæ–‡ä»¶åªæœ‰ {total} æ¡è®°å½•ï¼Œä¸å¤§äºè¦æ±‚çš„æ¯æ‰¹ {MAX_RECIPIENTS_PER_EMAIL} æ¡")
        print(f"   è¯·å¢å¤§CSVæ–‡ä»¶å†…å®¹ï¼Œæˆ–å‡å°é…ç½®æ–‡ä»¶ä¸­çš„ MAX_RECIPIENTS_PER_EMAIL")
        return
    
    # 5. è®¡ç®—æœ¬æ¬¡è¦åˆ‡å¤šå°‘æ¡ï¼ˆæ”¯æŒå¾ªç¯åˆ‡åˆ†ï¼‰
    remaining = total - current_index
    
    if remaining >= MAX_RECIPIENTS_PER_EMAIL:
        # å‰©ä½™è®°å½•è¶³å¤Ÿï¼Œç›´æ¥åˆ‡åˆ†
        batch_size = MAX_RECIPIENTS_PER_EMAIL
        start_idx = current_index
        end_idx = current_index + batch_size
        batch_rows = rows[start_idx:end_idx]
        
        print(f"ğŸ“Š æ­£å¸¸åˆ‡åˆ†ï¼šå‰©ä½™è®°å½•å……è¶³ï¼Œåˆ‡åˆ†ç¬¬ {current_index+1}-{end_idx} æ¡è®°å½•")
        
    else:
        # å‰©ä½™è®°å½•ä¸è¶³ï¼Œéœ€è¦å¾ªç¯ä»è¡¨å¤´è¡¥å……
        first_part = rows[current_index:]  # ä»å½“å‰ä½ç½®åˆ°æœ«å°¾
        needed = MAX_RECIPIENTS_PER_EMAIL - len(first_part)  # è¿˜éœ€è¦å¤šå°‘æ¡
        second_part = rows[:needed]  # ä»è¡¨å¤´è¡¥å……
        
        batch_rows = first_part + second_part
        batch_size = len(batch_rows)
        
        # è®¡ç®—æ˜¾ç¤ºç”¨çš„ç´¢å¼•ä¿¡æ¯
        print(f"ğŸ”„ å¾ªç¯åˆ‡åˆ†ï¼šå‰©ä½™ {remaining} æ¡è®°å½•ä¸è¶³ï¼Œä»è¡¨å¤´è¡¥å…… {needed} æ¡è®°å½•")
        print(f"   ç¬¬ä¸€æ®µï¼šExcelè¡Œ {current_index + 1 + (1 if HAS_HEADER else 0)} ~ {total + (1 if HAS_HEADER else 0)} ({len(first_part)} æ¡)")
        print(f"   ç¬¬äºŒæ®µï¼šExcelè¡Œ {1 + (1 if HAS_HEADER else 0)} ~ {needed + (1 if HAS_HEADER else 0)} ({len(second_part)} æ¡)")
    
    # ç»Ÿä¸€è®¡ç®—ç»“æŸç´¢å¼•ï¼ˆç”¨äºæ›´æ–°çŠ¶æ€ï¼‰
    end_idx = (current_index + batch_size) % total
    
    # è½¬æ¢ä¸ºExcelè¡Œå·æ˜¾ç¤ºï¼ˆæ›´ç”¨æˆ·å‹å¥½ï¼‰
    if remaining >= MAX_RECIPIENTS_PER_EMAIL:
        # æ­£å¸¸åˆ‡åˆ†çš„æƒ…å†µ
        excel_start_row = current_index + 1 + (1 if HAS_HEADER else 0)
        excel_end_row = (current_index + batch_size) + (1 if HAS_HEADER else 0)
        print(f"æœ¬æ¬¡å°†åˆ‡åˆ†è®°å½•åŒºé—´: Excelè¡Œ {excel_start_row} ~ {excel_end_row}, å…± {batch_size} æ¡")
    else:
        # å¾ªç¯åˆ‡åˆ†çš„æƒ…å†µï¼Œæ˜¾ç¤ºä¸¤æ®µ
        first_end_excel = total + (1 if HAS_HEADER else 0)
        second_end_excel = needed + (1 if HAS_HEADER else 0)
        print(f"æœ¬æ¬¡å°†åˆ‡åˆ†è®°å½•åŒºé—´: Excelè¡Œ {current_index + 1 + (1 if HAS_HEADER else 0)} ~ {first_end_excel} + Excelè¡Œ {1 + (1 if HAS_HEADER else 0)} ~ {second_end_excel}, å…± {batch_size} æ¡")

    # 6. ç”Ÿæˆ Excel æ–‡ä»¶
    batch_no_today = today_batches + 1
    filename = f"mail_batch_{today}_b{batch_no_today}.xlsx"

    if header:
        df = pd.DataFrame(batch_rows, columns=header)
    else:
        df = pd.DataFrame(batch_rows)

    df.to_excel(filename, index=False)
    print(f"å·²ç”Ÿæˆæ–‡ä»¶: {filename}")

    # 7. å†™æ—¥å¿— & æ›´æ–°è¿›åº¦
    if remaining >= MAX_RECIPIENTS_PER_EMAIL:
        # æ­£å¸¸åˆ‡åˆ†æƒ…å†µ
        excel_log_start = current_index + (1 if HAS_HEADER else 0)
        excel_log_end = (current_index + batch_size - 1) + (1 if HAS_HEADER else 0)
        append_log(today, batch_no_today, batch_size, excel_log_start, excel_log_end)
    else:
        # å¾ªç¯åˆ‡åˆ†æƒ…å†µï¼šè®°å½•ä¸¤æ®µä¿¡æ¯
        print(f"ğŸ“ è®°å½•å¾ªç¯åˆ‡åˆ†æ—¥å¿—...")
        first_log_end = (total - 1) + (1 if HAS_HEADER else 0)
        second_log_start = 0 + (1 if HAS_HEADER else 0)
        second_log_end = (needed - 1) + (1 if HAS_HEADER else 0)
        
        # ç¬¬ä¸€æ®µæ—¥å¿—
        append_log(today, f"{batch_no_today}-1", len(first_part), current_index + (1 if HAS_HEADER else 0), first_log_end)
        # ç¬¬äºŒæ®µæ—¥å¿—  
        append_log(today, f"{batch_no_today}-2", len(second_part), second_log_start, second_log_end)
    
    state["current_index"] = end_idx
    save_state(state)

    print(f"è¿›åº¦æ›´æ–°: current_index = {end_idx}")
    print("å®Œæˆã€‚")


if __name__ == "__main__":
    main()
